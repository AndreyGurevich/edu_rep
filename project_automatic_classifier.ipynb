{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 500\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "import re\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.model_selection  import KFold\n",
    "from sklearn.model_selection  import StratifiedKFold\n",
    "from sklearn.model_selection  import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "i_want_to_cv = False\n",
    "i_want_to_publish = True\n",
    "\n",
    "CORE_NUMBER = 4\n",
    "\n",
    "import moose_modules\n",
    "import os\n",
    "\n",
    "DEPLOY_FOLDER = \"deploy\"\n",
    "DATA_FOLDER = \"data\"\n",
    "OUTPUT_FOLDER = \"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Цель работы\n",
    "Автоматическая классификация обращений в техподдержку вместо используемого сейчас ручного труда.\n",
    "#### Описание ситуации\n",
    "* От пользователей поступает примерно 3000 обращений в месяц в техподдержку по различным каналам (телефон, почта, самостоятельная регистрация через ServiceDesk). Все эти обращения вручную классифицируются (зачем человек обратился) и маршрутизируются (кто будет делать).\n",
    "* Недавно произошла смена программной платформы ServiceDesk с одного продукта (CA Service Desk) на другой (ServiceNow). Поэтому большая историческая база заявок у нас есть в одной системе, а новые заявки обрабатывать надо в другой.\n",
    "* При смене платформы произошла полная смена классификатора. В старой было дерево предметных областей. В новой - дерево услуг, у каждой из которых есть категория, а у части - ещё подкатегория. При таком изменении подхода возникло несколько типов ситуаций:\n",
    "    * По некоторым предметным областям работы в новой системе просто не ведутся.\n",
    "    * У некоторых предметных областей из старой системы есть однозначное соответствие связки \"услуга-категория-подкатегория\" в новой.\n",
    "    * У многих произошло разбиение на 2-3 категории. Например, был \"Удалённый доступ через VPN\". Он превратился в \"Предоставление VPN\", \"Продление VPN\", \"Поддержка VPN\". Смысл разбиения: предоставление надо согласовывать со Службой информационной безопасности, продление - нет, а поддержкой занимаются совсем другие люди.\n",
    "    * Новый классификатор основан на услугах для пользователя, он ещё в процессе доработки, поэтому возникают ситуации дублирования. Например, когда пользователю надо установить клиент для VPN-подключения, это вроде бы \"Установка прочего ПО\". Но \"Поддержка VPN\" тоже подходит. Это сильно повлияет на оценку точности модели.\n",
    "* При смене платформы также инженеры получили возможность переназначить заявку, не меняя значение классификатора. В старой системе такого не было. Это сильно повысило удобство работы в системе. Но, как следствие, мы получили много заявок с неправильным выбранным значением услуги. Очевидная идея переклассифицировать существующие заявки по последнему решавшему не работает по ряду причин (не будем на них останавливаться). Так что при обработке данных значительная часть работы заключается в корректной переклассификации заявок в новую систему услуг-категорий-подкатегорий.\n",
    "\n",
    "#### Входные данные и постановка задачи\n",
    "Входные данные - письмо пользователя с описанием проблемы. На первом этапе внедрения обрабатываются только входящие письма, т.е. у нас есть заголовок письма, тело письма и его автор. \n",
    "\n",
    "На выходе надо получить:\n",
    "* Классификацию (услуга, категория, подкатегория).\n",
    "* Признак срочности (надо ли эту заявку решать раньше прочих).\n",
    "* Метрику уверенности в классификации.\n",
    "\n",
    "Особенность постановки задачи в том, что допускается ответ классификатора \"я не знаю\". Более того, этот ответ лучше, чем ошибочная классификация. Следствия такой постановки:\n",
    "* Можно игнорировать редкие классы, если модель на них будет выдавать ответ \"я не знаю\". Данные сильно несбалансированы (на этом остановимся позже), так что такая возможность сильно упрощает задачу.\n",
    "* Требуется соблюсти некий баланс между количеством заявок, по которым модель даёт уверенный ответ и количеством ошибок при этом. \n",
    "\n",
    "#### Этапы процесса:\n",
    "* Загрузить данные в датафреймы, склеить/переименовать столбцы\n",
    "* Провести очистку и лемматизацию текстов\n",
    "* Сгенерировать словарь токенов, которые не были распознаны лемматизатором. Список токенов отдельно проработать: что-то из него - это важный признак (названия ИС и подобное), а что-то - артефакты недостаточной очистки (например, \"доба\" - \"добавочный телефон\").\n",
    "* Разбить заявки из snow на части для обучения и для валидации. Часть для обучения склеить с заявками из CA. Модель проверять только на валидационной части заявок из SNOW\n",
    "* Обучить модель, учесть пороги, проверить метрики\n",
    "* Склеить все заявки из SNOW и CA SD, Обучить модель на результате, отправить в продуктив."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные о заявках можно получать двумя основными способами:\n",
    "* подключаться напрямую к БД и забирать данные оттуда\n",
    "* сделать предварительную выгрузку в Excel и работать уже с ней.\n",
    "\n",
    "У первого пути меньше лишних телодвижений, зато второй позволяет зафиксировать набор данных. Это важно в той ситуации, когда мы ищем оптимальный способ предварительной их трансформации перед обучением. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Number', 'Short description', 'Description', 'Business service',\n",
       "       'Category', 'Subcategory', 'Assignment group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_ca = pd.read_excel(\"data/raw_export_ca.xlsx\")\n",
    "#df_snow = pd.read_excel(\"data/raw_export_snow.xlsx\")\n",
    "\n",
    "df_ca = pd.read_excel(os.path.join(DATA_FOLDER, \"raw_export_ca.xlsx\"))\n",
    "df_snow = pd.read_excel(os.path.join(DATA_FOLDER, \"raw_export_snow.xlsx\"))\n",
    "\n",
    "\n",
    "df_snow.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Названия столбцов соответствуют названиям в интерфейсе ServiceNow. Но нам удобней работать с несколько иной структурой: \n",
    "* в первую очередь, надо склеить услугу, категорию и подкатегорию;\n",
    "* у заявки есть 'Краткое описание' и 'Описание' (полное). Бывают такие ситуации, когда краткое представляет из себя первые N символов полного, а бывают такие, что в кратком описании содержится очень важная информация, которой нет в полном описании. поэтому их надо склеить, избежав дублирования\n",
    "* столбцы, которые пока не участвуют в модели, удалим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_summary_and_description(row):\n",
    "    #print(row[\"summary\"])\n",
    "    \n",
    "    if row[\"description\"][:len(row[\"summary\"])+1] == row[\"summary\"]:\n",
    "        return row[\"description\"]\n",
    "    else:\n",
    "        return row[\"summary\"] + \" \" + row[\"description\"]\n",
    "\n",
    "\n",
    "df_snow.rename(columns={\"Номер\":\"ref_num\", \n",
    "                        \"Краткое описание\":\"summary\", \n",
    "                        \"Описание\":\"description\", \n",
    "                        \"Группа назначения\":\"AssignGroup\",\n",
    "                        \n",
    "                        \"Number\":\"ref_num\", \n",
    "                        \"Short description\":\"summary\", \n",
    "                        \"Description\":\"description\", \n",
    "                        \"Assignment group\":\"AssignGroup\",\n",
    "                        \"Business service\":\"Бизнес-услуга\", \n",
    "                        \"Category\":\"Категория\", \n",
    "                        \"Subcategory\":\"Подкатегория\"\n",
    "                       \n",
    "                       }, inplace = True)\n",
    "\n",
    "df_ca[\"ref_num\"] = df_ca[\"ref_num\"].astype(\"str\")\n",
    "df_ca[\"summary\"] = df_ca[\"summary\"].astype(\"str\")\n",
    "\n",
    "df_snow[\"description\"].fillna(\"\",inplace=True)\n",
    "df_ca[\"description\"].fillna(\"\",inplace=True)\n",
    "\n",
    "df_snow[\"category\"] = df_snow[\"Бизнес-услуга\"].fillna(\"\") + \"@\" + df_snow[\"Категория\"].fillna(\"\") + \"@\" + df_snow[\"Подкатегория\"].fillna(\"\")\n",
    "df_snow.drop(['Бизнес-услуга', 'Категория', 'Подкатегория'], axis=1, inplace = True)\n",
    "\n",
    "df_snow[\"raw_description\"] = df_snow[\"summary\"] + \" \" + df_snow[\"description\"]\n",
    "#df_snow[\"raw_description\"] = df_snow.apply(merge_summary_and_description, axis=1)\n",
    "df_ca[\"raw_description\"] = df_ca.apply(merge_summary_and_description, axis=1)\n",
    "\n",
    "df_snow[\"raw_description\"].fillna(\" \", inplace=True)\n",
    "df_ca[\"raw_description\"].fillna(\" \", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество заявок из ServiceNow: 17645\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество заявок из ServiceNow:\", df_snow.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные проблемы того, что мы получили в **raw_description**:\n",
    "* огромные блоки \"С уважением, бла-бла-бла\"\n",
    "* после которых идёт идёт абзац про коммерческую тайну в стиле \"Если вы получили это письмо по ошибке - не надо было его читать\"\n",
    "* ServiceNow этот абзац при обработке почты разбивает переносами строки на несколько, так что вырезать регулярками 1 абзац, в котором есть выражение \"коммерческая тайна\" нельзя.\n",
    "* вариантов этого текста около 10\n",
    "* некоторые слова из него могут быть важными маркерами для категоризации, так что выкинуть все эти слова через stop-list тоже нельзя\n",
    "* есть куча мусора в виде e-mail адресов, артефактов переписки типа \"Re: Re> на: ha>> fw :\" и т.д.\n",
    "* номера телефонов нам тоже не нужны\n",
    "\n",
    "Чем можно воспользоваться:\n",
    "* Номера документов имеют фиксированный формат и иногда по номеру понятно, к какому разделу ERP документ относится. Заменим их по формату на токены, DOCBUH, DOCLOGISTIC. Очевидно, что для задачи классификации информация \"в заявке указан номер бухгалтерского документа\" полезнее, чем сам номер.\n",
    "* IP и MAC адреса, также заменяем на фиксированные токены: IPADDRESS, MACADDRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_dict = {\n",
    "    r\"(\\bстаф\\b)|(\\bестафф\\b)\": \" estaff \",\n",
    "    r\"p:\\\\[\\w]+\": \" networkdisk \",\n",
    "    r\" р\\/с \" : \" расчетный счет \",\n",
    "    r\"( б\\/н )|( безнал )\" : \" безналичный \",\n",
    "    \"кому: servicedesk\": \" \",\n",
    "    \"wi-fi\": \"wifi\",\n",
    "\n",
    "    ##############################################################\n",
    "    ### много регулярок, местами включающих коммерческую тайну ###\n",
    "    ##############################################################\n",
    "    \n",
    "    \" скайп \": \" skype \",\n",
    "    \"\\t\": \" \",\n",
    "    \"\\n\": \" \"\n",
    "}\n",
    "    \n",
    "# def remove_trash(x):\n",
    "#     return re.sub(pattern=\"\\|\",repl=\" \",string=x,count=0)\n",
    "# \n",
    "\n",
    "def remove_multispaces(x):\n",
    "    return re.sub(pattern=\" +\",repl=\" \",string=str(x),count=0)\n",
    "\n",
    "\n",
    "def remove_brackets(x):\n",
    "    return re.sub(pattern=\"({)|(})\",repl=\" \",string=str(x),count=0)\n",
    "\n",
    "def remove_questions(x):\n",
    "    return re.sub(pattern=\"\\?\",repl=\"\",string=str(x),count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snow[\"text\"] = df_snow[\"raw_description\"].str.lower()\n",
    "df_snow.replace(to_replace = {\"text\": cleaning_dict}, inplace = True, regex=True )\n",
    "#df_snow[\"text2\"] = df_snow[\"raw_description\"].progress_apply(TEXT_PIPELINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca[\"text\"] = df_ca[\"raw_description\"].str.lower()\n",
    "df_ca.replace(to_replace = {\"text\": cleaning_dict}, inplace = True, regex=True )\n",
    "#df_ca[\"text2\"] = df_ca[\"raw_description\"].progress_apply(TEXT_PIPELINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас в столбцах text у нас частично очищенное от мусора описание заявки со всем многообразием словоформ русского языка. Чтобы от этого многообразия избавиться, надо провести лемматизацию.\n",
    "\n",
    "В качестве лемматизатора рассматривалось два варианта: *pymystem* и *pymorphy*.\n",
    "\n",
    "*pymorphy* очень удобен в использовании, очень быстр (особенно с lru_cache) но недостаточно сильно снижает многообразие словоформ.\n",
    "\n",
    "*pymystem* довольно жёсткий (лемматизирует то, что *pymorphy* уже считает леммой), быстрый в linux, но имеет очень большие накладные расходы (~0.7 секунды) на запуск под windows. Т.е. обрабатывать им слова по одному - дело долгое. Зато можно все тексты слить в один файл и его обработка пройдет довольно быстро. Кроме того, в качестве параметра можно подготовить fixlist, в котором заменять всякие сокращения и популярные опечатки. Важный минус - он просто игнорирует всю латиницу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ca[\"text\"].to_csv(\"data/df_ca_text.csv\", encoding=\"utf-8\")\n",
    "#df_snow[\"text\"].to_csv(\"data/df_snow_text.csv\", encoding=\"utf-8\")\n",
    "\n",
    "df_ca[\"text\"].to_csv(os.path.join(DATA_FOLDER, \"df_ca_text.csv\"), encoding=\"utf-8\")\n",
    "df_snow[\"text\"].to_csv(os.path.join(DATA_FOLDER, \"df_snow_text.csv\"), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "\n",
    "!\"C:\\Users\\agurevich\\.local\\bin\\mystem\" -cdl --fixlist C:\\Users\\agurevich\\python\\moose\\data\\ts_fixlist.txt C:\\Users\\agurevich\\python\\moose\\data\\df_ca_text.csv C:\\Users\\agurevich\\python\\moose\\data\\df_ca_text.out\n",
    "!\"C:\\Users\\agurevich\\.local\\bin\\mystem\" -cdl --fixlist C:\\Users\\agurevich\\python\\moose\\data\\ts_fixlist.txt C:\\Users\\agurevich\\python\\moose\\data\\df_snow_text.csv C:\\Users\\agurevich\\python\\moose\\data\\df_snow_text.out\n",
    "\n",
    "df_ca[\"text\"] = pd.read_csv(os.path.join(DATA_FOLDER, \"df_ca_text.out\"), header=None)[1]\n",
    "df_snow[\"text\"] = pd.read_csv(os.path.join(DATA_FOLDER, \"df_snow_text.out\"), header=None)[1]\n",
    "\n",
    "#df_ca[\"text\"] = df_ca[\"text\"].apply(only_letters)\n",
    "#df_snow[\"text\"] = df_snow[\"text\"].apply(only_letters)\n",
    "df_ca[\"text\"] = df_ca[\"text\"].apply(remove_brackets)\n",
    "df_snow[\"text\"] = df_snow[\"text\"].apply(remove_brackets)\n",
    "\n",
    "df_ca[\"text\"] = df_ca[\"text\"].apply(remove_multispaces)\n",
    "df_snow[\"text\"] = df_snow[\"text\"].apply(remove_multispaces)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В исходных данных много \"грязных\" данных с некорректной классификацией. В том числе заявок, классификация которых противоречит экспертному знанию. Функция moose_modules.reclassify_df применяет это знание.\n",
    "\n",
    "Т.к. нам надо будет делать стратифицированое разбиение на обучающую и тестовую выборки, выбросим редкие заявки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca, df_snow = moose_modules.reclassify_df(df_ca, df_snow)\n",
    "\n",
    "vc = pd.DataFrame(df_snow[\"category\"].value_counts())\n",
    "vc = vc[vc[\"category\"]<4]\n",
    "df_snow.drop(df_snow.index[df_snow[\"category\"].isin(vc.index)], axis=0, inplace = True)    \n",
    "\n",
    "vc = pd.DataFrame(df_ca[\"category\"].value_counts())\n",
    "vc = vc[vc[\"category\"]<4]\n",
    "df_ca.drop(df_ca.index[df_ca[\"category\"].isin(vc.index)], axis=0, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "df_snow.drop(df_snow.index[df_snow[\"category\"] == \"SAP@Служебные записки SAP@Выдача наличных средств\"], inplace=True)\n",
    "df_snow.drop(df_snow.index[df_snow[\"category\"] == \"Специфицирование@Доступ к специфицированию@\"], inplace=True)\n",
    "df_snow.drop(df_snow.index[df_snow[\"category\"] == \"ЦНСИ@Доступ к ЦНСИ@\"], inplace=True)\n",
    "df_snow.drop(df_snow.index[df_snow[\"category\"] == \"ТЕСС@Доступ к ТЕСС@\"], inplace=True)\n",
    "df_snow.drop(df_snow.index[df_snow[\"category\"] == \"ТЕСС@Поддержка ТЕСС@\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_dict = {}\n",
    "def collect_tokens(x):\n",
    "    for i in x.split():\n",
    "        if (i[-1]==\"?\"): strange_dict[i] = strange_dict.get(i, 0) + 1\n",
    "\n",
    "df_ca[\"text\"].apply(lambda x: collect_tokens(x))\n",
    "df_snow[\"text\"].apply(lambda x: collect_tokens(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_df =pd.DataFrame.from_dict(data =strange_dict, orient=\"index\")\n",
    "strange_df[0].fillna(\" \", inplace = True)\n",
    "strange_df[\"token\"]= strange_df.index\n",
    "strange_df[\"token\"] = strange_df[\"token\"].apply(remove_questions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = pd.read_csv(\"stopwords.csv\", encoding=\"utf8\",header=None)\n",
    "\n",
    "for stopped in stop_list[0]:\n",
    "    try:\n",
    "        #print(\"try\",stopped)\n",
    "        strange_df.drop( strange_df[strange_df[\"token\"]==stopped].index, inplace=True, axis=0)\n",
    "    except:\n",
    "        print(\"Not in strange_list:\",stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_df.drop(strange_df[strange_df[\"token\"].str.len()<2].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_df.sort_values(0,ascending=False).to_excel(os.path.join(OUTPUT_FOLDER, \"strange_df.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df_snow,train_size=.7, stratify=df_snow[\"category\"], random_state=17)\n",
    "\n",
    "train_data = pd.concat([df_ca, train_data], ignore_index=True)\n",
    "\n",
    "train_data = train_data[train_data[\"category\"].str.contains(\"@\") ]\n",
    "test_data = test_data[test_data[\"category\"].str.contains(\"@\") ]\n",
    "\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53780, 7)\n",
      "(5042, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные подготовлены, начнём обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = pd.DataFrame(test_data[[\"ref_num\", \"text\", \"raw_description\",\"category\"]])\n",
    "target = train_data[\"category\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2, max_df=1.0,  strip_accents=None,ngram_range = (1, 3), stop_words=list(stop_list))\n",
    "train_vectorised_text = vectorizer.fit_transform(train_data[\"text\"])\n",
    "test_vectorised_text = vectorizer.transform(test_data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объём словаря: 391111\n"
     ]
    }
   ],
   "source": [
    "print(\"Объём словаря:\",len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cv(model, cv_param_grid):\n",
    "    gridCV = GridSearchCV(model, \n",
    "                          param_grid=cv_param_grid, \n",
    "                          scoring='f1_weighted', \n",
    "                          cv=kfold, \n",
    "                          n_jobs=CORE_NUMBER,\n",
    "                          verbose=1)    \n",
    "    t0 = time()\n",
    "    gridCV.fit(train_vectorised_text, target)\n",
    "    duration = time() - t0\n",
    "    print(\"GridCV done in %fs \" % (duration))\n",
    "    return (gridCV.best_params_ ,gridCV.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier F1 score 0.700764459966\n"
     ]
    }
   ],
   "source": [
    "clf_sgd_bow = SGDClassifier() #class_weight=snow_dict\n",
    "clf_sgd_bow_cv_params = {'alpha':[1e-05],\n",
    "                          'penalty':['l2', None],\n",
    "                          'loss': ['modified_huber'],\n",
    "                          'learning_rate': [\"constant\"],\n",
    "                          'class_weight' : [None],\n",
    "                          'eta0' :[0.3,0.4,0.5],\n",
    "                          'n_jobs':[CORE_NUMBER],\n",
    "                        'random_state':17\n",
    "                         }\n",
    "\n",
    "clf_sgd_bow_train_params = {'alpha': 1e-05,\n",
    "                             'class_weight': None,\n",
    "                             'eta0': 0.1,\n",
    "                             'learning_rate': 'constant',\n",
    "                             'loss': 'modified_huber',\n",
    "                             'penalty': None,\n",
    "                             'n_jobs':CORE_NUMBER,\n",
    "                             'random_state':17 }\n",
    "\n",
    "if i_want_to_cv:\n",
    "    cv_temp = make_cv(clf_sgd_bow, clf_sgd_bow_cv_params)\n",
    "    print(cv_temp)\n",
    "    clf_sgd_bow_train_params = cv_temp[0]\n",
    "    \n",
    "\n",
    "clf_sgd_bow.set_params(**clf_sgd_bow_train_params)\n",
    "clf_sgd_bow.fit(train_vectorised_text, target)\n",
    "\n",
    "\n",
    "sgd_f1_score = f1_score(Y_test [\"category\"],clf_sgd_bow.predict(test_vectorised_text), average=\"weighted\", labels=clf_sgd_bow.classes_)\n",
    "print(\"SGDClassifier F1 score\", sgd_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction done in 1.120045s \n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "Y_test [\"predicted_bow\"] = clf_sgd_bow.predict(vectorizer.transform(Y_test[\"text\"]))\n",
    "\n",
    "duration = time() - t0\n",
    "print(\"Prediction done in %fs \" % (duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = pd.read_csv(os.path.join(DATA_FOLDER, \"thresholds.csv\"), encoding=\"utf-8\", delimiter=\";\",index_col=\"category\",decimal=\",\")\n",
    "if (not (\"f1_df\" in locals())):\n",
    "    f1_df = pd.DataFrame(Y_test[\"category\"].value_counts())\n",
    "    f1_df.rename(columns={\"category\":\"count\"},inplace=True)\n",
    "    \n",
    "    f1_df = pd.concat([f1_df, thresholds], axis=1, join_axes=[f1_df.index])\n",
    "f1_df[\"threshold\"] = thresholds[\"threshold\"]\n",
    "f1_df[\"metric_name\"] = thresholds[\"metric_name\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в выводе следующей ячейки что-то есть, то у нас появились новые категории, для которых не определены пороги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>threshold</th>\n",
       "      <th>metric_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [count, threshold, metric_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df[f1_df[\"metric_name\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_temp = pd.DataFrame(np.sort(clf_sgd_bow.predict_proba(vectorizer.transform(Y_test[\"text\"])), axis=1))\n",
    "Y_test[\"max_proba\"] = df_temp[df_temp.shape[1]-1]\n",
    "Y_test[\"second_proba\"] = df_temp[df_temp.shape[1]-2]    \n",
    "Y_test[\"delta\"] = Y_test[\"max_proba\"] -  Y_test[\"second_proba\"]   \n",
    "\n",
    "#Y_test2 =pd.concat([Y_test, pd.DataFrame([delta, max_proba, second_proba]).transpose().rename(columns={0:\"delta\", 1:\"max_proba\", 2:\"second_proba\"})], axis=1)\n",
    "Y_test[\"new_metric\"] = Y_test[\"max_proba\"]/Y_test[\"second_proba\"]\n",
    "Y_test[\"log_new_metric\"] = np.log(Y_test[\"max_proba\"]/Y_test[\"second_proba\"]) / np.log(Y_test[\"new_metric\"][Y_test[\"new_metric\"]!=float(\"inf\")].max())\n",
    "Y_test[\"bow_right\"] = (Y_test[\"category\"] == Y_test[\"predicted_bow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df[\"bow_is_sure_count\"]=0\n",
    "f1_df[\"bow_is_right_count\"]=0\n",
    "Y_test[\"sure\"]=False\n",
    "for cat_name in f1_df.index:\n",
    "    #print(cat_name)\n",
    "    f1_df.loc[cat_name,\"bow_is_sure_count\"] = Y_test[(Y_test[f1_df.loc[cat_name, \"metric_name\"]]>f1_df.loc[cat_name, \"threshold\"])\n",
    "                                            &(Y_test[\"predicted_bow\"]==cat_name) ].shape[0]\n",
    "    Y_test[\"sure\"][(Y_test[f1_df.loc[cat_name, \"metric_name\"]]>f1_df.loc[cat_name, \"threshold\"])\n",
    "                                            &(Y_test[\"predicted_bow\"]==cat_name) ]=True\n",
    "    f1_df.loc[cat_name,\"bow_is_right_count\"] = Y_test[(Y_test[f1_df.loc[cat_name, \"metric_name\"]]>f1_df.loc[cat_name, \"threshold\"])\n",
    "                                            &(Y_test[\"predicted_bow\"]==cat_name) \n",
    "                                            &(Y_test[\"predicted_bow\"]==Y_test[\"category\"])].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогнозов: 3800\n",
      "Ошибок 721\n",
      "Процент прогнозов 0.753669178897\n",
      "Процент правильных 0.810263157895\n",
      "| 3800 | 721 | 0.753669178897 | 0.810263157895\n",
      "|5042| 3800 | 721 | 0.754 |0.810|0.70076\n"
     ]
    }
   ],
   "source": [
    "print(\"Прогнозов:\", f1_df[\"bow_is_sure_count\"].sum())\n",
    "print(\"Ошибок\", f1_df[\"bow_is_sure_count\"].sum()-f1_df[\"bow_is_right_count\"].sum())\n",
    "print(\"Процент прогнозов\", f1_df[\"bow_is_sure_count\"].sum()/f1_df[\"count\"].sum())\n",
    "print(\"Процент правильных\", f1_df[\"bow_is_right_count\"].sum()/f1_df[\"bow_is_sure_count\"].sum())\n",
    "print(\"|\", f1_df[\"bow_is_sure_count\"].sum(),\n",
    "      \"|\", f1_df[\"bow_is_sure_count\"].sum()-f1_df[\"bow_is_right_count\"].sum(),\n",
    "      \"|\", f1_df[\"bow_is_sure_count\"].sum()/f1_df[\"count\"].sum(),\n",
    "      \"|\", f1_df[\"bow_is_right_count\"].sum()/f1_df[\"bow_is_sure_count\"].sum()\n",
    "     )\n",
    "f1_df[\"acc\"] = f1_df[\"bow_is_right_count\"]/f1_df[\"bow_is_sure_count\"]\n",
    "\n",
    "\n",
    "if (\"f1_bow\") in f1_df.columns: f1_df[\"f1_bow_prev\"]=f1_df[\"f1_bow\"]\n",
    "f1_df[\"f1_bow\"] = f1_score(Y_test [\"category\"],Y_test [\"predicted_bow\"], average=None, labels=f1_df.index)\n",
    "if (\"f1_bow_prev\") in f1_df.columns: \n",
    "    f1_df[\"f1_bow_d\"]=f1_df[\"f1_bow\"]-f1_df[\"f1_bow_prev\"] \n",
    "else: f1_df[\"f1_bow_d\"]=0\n",
    "\n",
    "# вывести счёт\n",
    "#print(\"bow\", str(f1_score(Y_test [\"category\"],Y_test [\"predicted_bow\"], average=\"weighted\", labels=f1_df.index)))\n",
    "#print(\"cfm\", str(f1_score(Y_test [\"category\"],Y_test [\"predicted_cfm\"], average=\"weighted\", labels=f1_df.index)))\n",
    "#print(\"rf\", str(f1_score(Y_test [\"category\"],Y_test [\"predicted_rf\"], average=\"weighted\", labels=f1_df.index)))\n",
    "#print(\"xgb\", str(f1_score(Y_test [\"category\"],Y_test [\"predicted_xgb\"], average=\"weighted\", labels=f1_df.index)))\n",
    "#print(\"xgb bow\", str(f1_score(Y_test [\"category\"],Y_test [\"predicted_XGB_bow\"], average=\"weighted\", labels=f1_df[\"labels\"])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"|{4:d}| {0:d} | {1:2d} | {2:0.3f} |{3:0.3f}|{5:0.5f}\".format(f1_df[\"bow_is_sure_count\"].sum()\n",
    "                                              , f1_df[\"bow_is_sure_count\"].sum()-f1_df[\"bow_is_right_count\"].sum()\n",
    "                                              , f1_df[\"bow_is_sure_count\"].sum()/f1_df[\"count\"].sum()\n",
    "                                              , f1_df[\"bow_is_right_count\"].sum()/f1_df[\"bow_is_sure_count\"].sum()\n",
    "                                              ,test_data.shape[0]\n",
    "                                            ,sgd_f1_score\n",
    "                                                           ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Комментарий|Размер теста|Прогнозов|Ошибок|Процент прогнозов|Процент правильных|F1 модели\n",
    "---|---|---|---|---|---\n",
    "|4897| 3666 | 651 | 0.749 |0.822\n",
    "удалил tел|4897| 3671 | 655 | 0.750 |0.822\n",
    "замена на lotusnotes|4897| 3671 | 654 | 0.750 |0.822|0.712\n",
    ".+ доб\\..+|4897| 3663 | 650 | 0.748 |0.823|0.71372\n",
    ".+ моб\\..+|4897| 3680 | 657 | 0.751 |0.821|0.70894\n",
    "пошаманил с регулярками и \\b вместо \\s|4897| 3681 | 656 | 0.752 |0.822|0.70931\n",
    "|4897| 3688 | 663 | 0.753 |0.820|0.71014\n",
    "|4897| 3695 | 664 | 0.755 |0.820|0.70989\n",
    "oppa|4897| 3695 | 666 | 0.755 |0.820|0.70989\n",
    "накинул данных|5042| 3800 | 721 | 0.754 |0.810|0.70076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col0 {\n",
       "            background-color:  #2ecc71;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col1 {\n",
       "            background-color:  #eafaf1;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col3 {\n",
       "            background-color:  #2ecc71;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col4 {\n",
       "            background-color:  #88e2ae;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col5 {\n",
       "            background-color:  #2ecc71;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col6 {\n",
       "            background-color:  #eafaf1;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col0 {\n",
       "            background-color:  #32cd74;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col1 {\n",
       "            background-color:  #e6f9ee;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col3 {\n",
       "            background-color:  #59d78e;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col4 {\n",
       "            background-color:  #2ecc71;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col5 {\n",
       "            background-color:  #6adb9a;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col6 {\n",
       "            background-color:  #eafaf1;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col0 {\n",
       "            background-color:  #a9eac4;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col1 {\n",
       "            background-color:  #2ecc71;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col3 {\n",
       "            background-color:  #88e2ae;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col4 {\n",
       "            background-color:  #b8eecf;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col5 {\n",
       "            background-color:  #50d488;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col6 {\n",
       "            background-color:  #eafaf1;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col0 {\n",
       "            background-color:  #e9faf0;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col1 {\n",
       "            background-color:  #8ce3b1;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col3 {\n",
       "            background-color:  #afecc9;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col4 {\n",
       "            background-color:  #eafaf1;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col5 {\n",
       "            background-color:  #2ecc71;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col6 {\n",
       "            background-color:  #eafaf1;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col0 {\n",
       "            background-color:  #eafaf1;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col1 {\n",
       "            background-color:  #e1f8eb;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col3 {\n",
       "            background-color:  #eafaf1;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col4 {\n",
       "            background-color:  #32cd74;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col5 {\n",
       "            background-color:  #eafaf1;\n",
       "        }    #T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col6 {\n",
       "            background-color:  #eafaf1;\n",
       "        }</style>  \n",
       "<table id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >count</th> \n",
       "        <th class=\"col_heading level0 col1\" >threshold</th> \n",
       "        <th class=\"col_heading level0 col2\" >metric_name</th> \n",
       "        <th class=\"col_heading level0 col3\" >bow_is_sure_count</th> \n",
       "        <th class=\"col_heading level0 col4\" >acc</th> \n",
       "        <th class=\"col_heading level0 col5\" >f1_bow</th> \n",
       "        <th class=\"col_heading level0 col6\" >f1_bow_d</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3level0_row0\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col0\" class=\"data row0 col0\" >507</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col1\" class=\"data row0 col1\" >0.5</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col2\" class=\"data row0 col2\" >max_proba</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col3\" class=\"data row0 col3\" >491</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col4\" class=\"data row0 col4\" >0.881874</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col5\" class=\"data row0 col5\" >0.865116</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row0_col6\" class=\"data row0 col6\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3level0_row1\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col0\" class=\"data row1 col0\" >501</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col1\" class=\"data row1 col1\" >0.55</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col2\" class=\"data row1 col2\" >max_proba</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col3\" class=\"data row1 col3\" >404</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col4\" class=\"data row1 col4\" >0.920792</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col5\" class=\"data row1 col5\" >0.814815</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row1_col6\" class=\"data row1 col6\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3level0_row2\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col0\" class=\"data row2 col0\" >311</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col1\" class=\"data row2 col1\" >2.5</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col2\" class=\"data row2 col2\" >new_metric</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col3\" class=\"data row2 col3\" >309</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col4\" class=\"data row2 col4\" >0.860841</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col5\" class=\"data row2 col5\" >0.836941</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row2_col6\" class=\"data row2 col6\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3level0_row3\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col0\" class=\"data row3 col0\" >208</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col1\" class=\"data row3 col1\" >1.5</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col2\" class=\"data row3 col2\" >new_metric</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col3\" class=\"data row3 col3\" >230</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col4\" class=\"data row3 col4\" >0.83913</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col5\" class=\"data row3 col5\" >0.865342</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row3_col6\" class=\"data row3 col6\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3level0_row4\" class=\"row_heading level0 row4\" >4</th> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col0\" class=\"data row4 col0\" >205</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col1\" class=\"data row4 col1\" >0.6</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col2\" class=\"data row4 col2\" >max_proba</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col3\" class=\"data row4 col3\" >111</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col4\" class=\"data row4 col4\" >0.918919</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col5\" class=\"data row4 col5\" >0.707447</td> \n",
       "        <td id=\"T_ce41f726_1d34_11e8_8246_2c56dc9bd4d3row4_col6\" class=\"data row4 col6\" >0</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x48b992b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = sns.light_palette(\"#2ecc71\", as_cmap=True)\n",
    "\n",
    "\n",
    "\n",
    "# Код для соблюдения NDA\n",
    "if i_want_to_publish:\n",
    "    f1_df.index=np.arange(0,f1_df.shape[0])\n",
    "    s = f1_df[[\"count\",\"threshold\",\"metric_name\",\"bow_is_sure_count\",\"acc\", \"f1_bow\",\"f1_bow_d\"]].head().style.background_gradient(cmap=cm)\n",
    "else:\n",
    "    s = f1_df[[\"count\",\"threshold\",\"metric_name\",\"bow_is_sure_count\",\"acc\", \"f1_bow\",\"f1_bow_d\"]].style.background_gradient(cmap=cm)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!telegram-send \"wake up\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка к установке\n",
    "* объединим train и test, пересчитаем модель заново\n",
    "* выложим в папку deploy всё то, что надо будет переносить во Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([train_data, test_data], ignore_index=True)\n",
    "merged_vectorised_text = vectorizer.fit_transform(merged[\"text\"])\n",
    "clf_sgd_bow.fit(merged_vectorised_text, merged[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf_sgd_bow, os.path.join(DEPLOY_FOLDER, \"clf_sgd_snow.pkl\")) \n",
    "joblib.dump(vectorizer, os.path.join(DEPLOY_FOLDER, \"vec_snow.pkl\")) \n",
    "joblib.dump(cleaning_dict, os.path.join(DEPLOY_FOLDER, \"cleaning_dict.pkl\")) \n",
    "\n",
    "thresholds.to_csv(os.path.join(DEPLOY_FOLDER, \"thresholds.csv\"), encoding=\"utf-8\", sep=\";\",decimal=\",\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
