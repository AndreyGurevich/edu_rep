>• Вы знаете `математику`, `линейную алгебру`, `статистику`, `алгоритмы` и применяете их в `программировании`.

В моём дипломе написано "прикладной математик - системный программист". Я не применяю в программировании дифференцирование, потому что за меня это сделали разработчики фреймворков. Для запуска градиентного спуска не надо руками считать частные производные. Но я понимаю, что "под капотом" именно они и до определённого этапа этого достаточно. Также и с алгоритмами: если мне надо отсортировать датафрейм, я воспользуюсь `pandas.DataFrame.sort_values`. Если же мне потребуется регулярно в высоконагруженном проде сортировать огромные массивы данных - это будет поводом поискать подходящий для данной ситуации инструмент. На мой взгляд, быстрое исполнение алгоритма, низкий расход памяти, высокая скорость разработки - это классический пример "выбери любые два из трёх".

>• Вы писали на `C++`, `Python`, `C#`, `Java`, а освоить `новый язык` для вас не проблема.

В формулировке "писали" это будет следующий список: `Basic`, `Pascal`, `Object Pascal`, `C`, `C++` (диплом), `Java` (дополнения к `hp service desk`), `JavaScript` (и `клиентский`, и `Node.js`), безымянный недокументированный C-подобный язык скриптов `CA ServiceDesk`. `HTML`, `PL/SQL`. Сейчас вот `Python`. На базовом уровне очередной язык и правда не проблема. Долгое погружение требуется для таких тонкостей, как разница между `==` и `===` в `JavaScript`, например.
>• Вы можете объяснить что такое `машинное обучение`, почему `продукционные системы` не `ML` и подавно не `DL`, понимаете для чего нужен `градиентный спуск` и  как работает `backpropagation`, чем отличаются `сверточные` сети от `рекуррентных`, что дает `дропаут` и как `аугментировать датасет`.

Сложный философский вопрос, на мой взгляд. Обычные для ML деревья решений создаются с учётом вычисляемых формализованных критериев информативности и имеют один корень. Продукционные системы могут представлять из себя список "Если А, то Б", созданный человеком на основе экспертного знания. Этот список в некоторых случаях можно превратить в дерево, он может быть как эффективней, так и хуже автоматический сгенерированного. ML-алгоритм может в результате своей работы выделить те же самые правила. Мне кажется, это скорее вопрос для дискуссии в формате "как вы думаете?", нежели "докажите, почему".
`Свёрточные слои` сети из нескольких элементов данных собирают один вывод для следующего слоя. Замечательный пример - это средний цвет 9 соседних пикселей картинки.
`Рекуррентные сети` ещё не изучал. Хоть они и должны хорошо подходить для задачи анализа текста, с моим проектом отлично справилась простая линейная модель, которая гораздо проще в эксплуатации.
`Градиентный спуск` - хороший способ найти оптимальные веса для модели. Если он стохастический - то ещё и быстрый. Главное не ошибиться с выбором коэффициента `etha`.
`аугментировать датасет` - искуственно расширить его за счёт немного изменённых данных. Картинки повернуть/приблизить (если применимо в задаче), тексты тоже можно немного изменить. К примеру, в проекте классификатора заявок можно взять заявку редкого класса и сделать ещё много похожих, меняя незначительные подробности в описании.
Про `дропаут` знаю на уровне "Это из нейросетей. Судя по названию, что-то откуда-то выбрасывают". Специально не стал читать подробнее перед написанием этого текста, потому что как следует в любей теме можно разобраться только на практике.
>• Вы использовали `t-SNE` и `SVD`, применяли `K-Means`, строили `RandomForest` и можете объяснить что такое `XGBoost`.

`t-SNE`, `SVD`,`K-Means` не использовал. `RandomForest` - ансамбль случайно-разных деревьев решенией. `XGBoost` - тоже ансамбль деревьев решенией, но каждое следующее строится так, чтобы уменьшить функцию потерь.
>• Вы создавали модели на `Tensorflow`, `PyTorch`, `Keras` & co, использовали `Numpy`, `Sklearn`, `Pandas`, `Jupiter` и т.п.

Запускал готовые модели на `Tensorflow`, `PyTorch`, `Keras`. Создавал своё, используя `Numpy`, `Sklearn`, `Pandas`, `Jupiter`
>• У вас есть `культура` проведения `экспериментов` и опыт `внедрения` решений, возможно вы `управляли командой`.

В процессе разработки классификатора заявок были десятки, если не сотни экспериментов с алгоритмом предобработки, гиперпараметрами модели, самими моделями. Описание и результат сводил в табличку. Такой способ плохо масштабируется, но в данной ситуации подошёл.
Командой управлял и в "Протеке" (передыдущее место работы, регулярно замещал руководителя Call-центра и помогал в повседневной работе), и в Техносерве (по направлению администрирования Service desk ставлю часть задач напарнику, по машинному обучению я РП и разработчик python-части, напарник отвечает за интеграцию)
>• Вы разрабатывали модели `глубокого обучения` в области `компьютерного зрения`, игрались с `GAN`.

Нет
>• Вы занимались `большими данными` и использовали `Hadoop`, `MapReduce`, `Spark`.

Нет, работал с базами Oracle размером не больше 50-60 Гб.
>• А может, вы талантливый и ловкий `DevOps`?

Наверное, нет. Я просто использую Git для хранения кода, а код этот генерирует всё необходимое для удобного переноса с DEV-окружения на TEST и на PROD. В планах - увеличить уровень автоматизации процесса, избавиться от простоя при обновлении версии (как это сделать - понятно, надо просто потратить время).
>• Вы можете правильно раскрыть аббревиатуру `NLP` и рассказать суть подходов `Word2Vec`.

Если вторая половина вопроса про `Word2Vec`, то "правильно" - это `Natural Language Processing`. А Word2Vec создаёт векторное представление слов. За счёт этого появляются такие интересные возможности, как поиск близких по смыслу слов и учёт отношений слов. Например, мы знаем, как слово `король` относится к слову `мужчина` и хотим узнать, что будет аналогом для слова `женщина`. `Word2Vec`подскажет, что `королева`.
>• Вы знаете как добавить `Attention` к вашей модели или готовы разобраться погуглив на arxiv-sanity.com.

Я готов разобраться, что такое `Attention` в данном контексте. Спросив или погуглив. А потом добавить это самое.
>• Вы представляете что такое `Seq2Seq` и даже применяли его на практике.

Нет
>• У вас есть код, которым вы гордитесь и можете показать его на `гитхабе`.

https://github.com/AndreyGurevich/edu_rep/blob/master/project_automatic_classifier.ipynb - "презентация" текущего проекта по ML.
https://github.com/AndreyGurevich/Chrome_cashbackru_plugin - мне понравилась идея кэшбэк-сервисов cashback.ru и letyshops.com, но не нравилось, что надо проверять каждый интернет-магазин на возможность кэшбэка. Логично, что эту проверку можно автоматизировать расширением браузера. У letyshops было готовое (но не отдавать же недоверенным людям столько информации), а cachback.ru пошли на контакт, дали API для получения списка магазинов, идею про использование объекта localStorage браузера и я написал себе свой плагин, с проверкой и оповещением. Оказалось, что им ещё человек 10 пользуется.
В гитхабе есть ещё некоторое количество моего кода, но я не готов сказать, что горжусь им.

>• Вы писали `диалоговые модели` или работали с `извлечением смысла из текстов`, а то и с `вопросно-ответными системами`, слышали про `датасет Baby` и про `сети с памятью` более длинной чем у `LSTM`.

Нет, но это было бы интересное развитие моего опыта работы с короткими текстами с большим количеством мусора и опечаток.
>• Вы хотели бы участвовать в разработке моделей, похожих на `CommAI`.

Предпочёл бы сначала хорошо разобраться, что такое CommAI и как оно работает, что нам нужно и почему готовый инструмент не подходит и надо создавать похожий. Это могут быть соображения повышения точности, производительности, информационной безопасности, экономики, чего угодно. Но должны быть причины.

>• Вы обучали `RL`-модели, готовы рассказать на чем основан `Q-Learning` и изложить суть топовых алгоритмов.

нет.
>• Вам знакомы понятия `чистый код`, `архитектура`, `микросервисы`, `деплой`, `продакшн`, `рефакторинг`, `кодревью`, `паттерны`, `DRY`, `MVP`, `TDD`, ~BDSM~.

`DRY` пришлось гуглить. Раньше это называлось `функциональный подход` и `повторное использование кода`. Теперь распространили идею на документацию (вполне здраво) и придумали новый термин.
>• Вы `преподавали`, выступали на `конференциях`, участвовали в `соревнованиях`, проводили `воркшопы`,  или хотели бы проявиться в этом.

Когда-то я даже 1С бухгалтерам преподавал... Вообще на работе мне нравится, когда ко мне прислушиваются не потому что положено, а потому что я знаю.
В конференциях/воркшопах не участвовал, в соревнованиях в основном на каггле: https://goo.gl/qk5uXB
