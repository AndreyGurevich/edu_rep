Метод стохастического градиента
Преимущества:
он легко реализуется, 
может быть обобщён на нелинейной модели. 
Он может быть использован с самыми разными функциями потерь, 
может быть использован для больших данных,

Недостатки. 
Во-первых, как правило, функционалы, которые получаются в задачах машинного обучения, являются многоэкстремальными, а какие-то обоснования сходимости для метода стохастического градиента известны главным образом только для выпуклых функций. А мы пытаемся его применять для невыпуклых функций, поэтому сходимость есть, но она только локальная, к локальному экстремуму, и как найти хорошее начальное приближение, которое приведёт нас к удачному локальному экстремуму, это важный вопрос. 
Дальше, возможна также расходимость или очень медленная сходимость, поэтому нужно знать, какими способами можно ускорить сходимость этого метода. 
Наконец, в линейных моделях возможно переобучение из-за неприятного эффекта, который называется мультиколлинеарностью