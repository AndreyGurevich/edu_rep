{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Introduction to NLTK\n",
    "\n",
    "In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Analyzing Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.probability import FreqDist\n",
    "#from nltk.book import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# If you would like to work with the raw text you can use 'moby_raw'\n",
    "with open('moby.txt', 'r') as f:\n",
    "    moby_raw = f.read()\n",
    "    \n",
    "# If you would like to work with the novel in nltk.Text format you can use 'text1'\n",
    "moby_tokens = nltk.word_tokenize(moby_raw)\n",
    "text1 = nltk.Text(moby_tokens)\n",
    "dist = FreqDist(text1)\n",
    "moby_frequencies = FreqDist(moby_tokens)\n",
    "moby_frequency_frame = pd.DataFrame(moby_frequencies.most_common(), columns=[\"token\", \"frequency\"])\n",
    "moby_words = moby_frequency_frame[moby_frequency_frame.token.str.isalpha()]\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict(dist, orient='index')\n",
    "df.sort_values(0, ascending=False, inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={0:\"count\", \"index\":\"token\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "How many tokens (words and punctuation symbols) are in text1?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254989"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_one():\n",
    "    \n",
    "    return len(nltk.word_tokenize(moby_raw)) # or alternatively len(text1)\n",
    "\n",
    "example_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "How many unique tokens (unique words and punctuation) does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20755"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_two():\n",
    "    \n",
    "    return len(set(nltk.word_tokenize(moby_raw))) # or alternatively len(set(text1))\n",
    "\n",
    "example_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "After lemmatizing the verbs, how many unique tokens does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16900"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def example_three():\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in text1]\n",
    "\n",
    "    return len(set(lemmatized))\n",
    "\n",
    "example_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08139566804842562"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    \n",
    "    \n",
    "    return example_two()/example_one()\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What percentage of tokens is 'whale'or 'Whale'?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4125668166077752"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "\n",
    "    whales_num = dist[\"whale\"] + dist[\"Whale\"]\n",
    "    \n",
    "    return 100*whales_num/example_one() # Your answer here\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?\n",
    "\n",
    "*This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19204),\n",
       " ('the', 13715),\n",
       " ('.', 7308),\n",
       " ('of', 6513),\n",
       " ('and', 6010),\n",
       " ('a', 4545),\n",
       " ('to', 4515),\n",
       " (';', 4173),\n",
       " ('in', 3908),\n",
       " ('that', 2978),\n",
       " ('his', 2459),\n",
       " ('it', 2196),\n",
       " ('I', 2097),\n",
       " ('!', 1767),\n",
       " ('is', 1722),\n",
       " ('--', 1713),\n",
       " ('with', 1659),\n",
       " ('he', 1658),\n",
       " ('was', 1639),\n",
       " ('as', 1620)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    \n",
    "    res_list = []\n",
    "    for i in df[:20].iterrows():\n",
    "        #print(i[1][\"token\"])\n",
    "        res_list.append((i[1][\"token\"], i[1][\"count\"]))\n",
    "    \n",
    "    return  res_list # Your answer here\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What tokens have a length of greater than 5 and frequency of more than 150?\n",
    "\n",
    "*This function should return a sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Captain',\n",
       " 'Pequod',\n",
       " 'Queequeg',\n",
       " 'Starbuck',\n",
       " 'almost',\n",
       " 'before',\n",
       " 'himself',\n",
       " 'little',\n",
       " 'seemed',\n",
       " 'should',\n",
       " 'though',\n",
       " 'through',\n",
       " 'whales',\n",
       " 'without']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    freqwords = [w for w in dist if len(w) > 5 and dist[w] > 150]\n",
    "    \n",
    "    return  sorted(freqwords) # Your answer here\n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Find the longest word in text1 and that word's length.\n",
    "\n",
    "*This function should return a tuple `(longest_word, length)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"twelve-o'clock-at-night\", 23)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_five():\n",
    "    \n",
    "    df[\"token_len\"] = df[\"token\"].str.len()\n",
    "    \n",
    "    return (df.sort_values(\"token_len\", ascending=False).reset_index().iloc[0, 1], df.sort_values(\"token_len\", ascending=False).reset_index().iloc[0, 3])   # Your answer here\n",
    "\n",
    "answer_five()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What unique words have a frequency of more than 2000? What is their frequency?\n",
    "\n",
    "\"Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.\"\n",
    "\n",
    "*This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>19204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>13715</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>7308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>6513</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>6010</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>4545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>to</td>\n",
       "      <td>4515</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>;</td>\n",
       "      <td>4173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>3908</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>that</td>\n",
       "      <td>2978</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>his</td>\n",
       "      <td>2459</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it</td>\n",
       "      <td>2196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I</td>\n",
       "      <td>2097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  count  token_len\n",
       "0      ,  19204          1\n",
       "1    the  13715          3\n",
       "2      .   7308          1\n",
       "3     of   6513          2\n",
       "4    and   6010          3\n",
       "5      a   4545          1\n",
       "6     to   4515          2\n",
       "7      ;   4173          1\n",
       "8     in   3908          2\n",
       "9   that   2978          4\n",
       "10   his   2459          3\n",
       "11    it   2196          2\n",
       "12     I   2097          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"count\"]>2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13715, 'the'),\n",
       " (6513, 'of'),\n",
       " (6010, 'and'),\n",
       " (4545, 'a'),\n",
       " (4515, 'to'),\n",
       " (3908, 'in'),\n",
       " (2978, 'that'),\n",
       " (2459, 'his'),\n",
       " (2196, 'it'),\n",
       " (2097, 'I')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_six():\n",
    "    res_list = []\n",
    "    freqwords = [df[df[\"count\"]>2000]]\n",
    "    token_num = example_one()\n",
    "    for i in df[df[\"count\"]>2000].iterrows():\n",
    "        if (i[1][\"token\"].isalpha()):\n",
    "            res_list.append((i[1][\"count\"], i[1][\"token\"]))\n",
    "        #print(i[1] )\n",
    "    return res_list # Your answer here\n",
    "\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What is the average number of tokens per sentence?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.881952902963864"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_seven():\n",
    "    df_sentences = pd.DataFrame(nltk.sent_tokenize(moby_raw), columns=[\"sent\"])\n",
    "    df_sentences[\"tokens_count\"] = df_sentences[\"sent\"].apply(lambda x: len(nltk.word_tokenize(x))) \n",
    "    \n",
    "    \n",
    "    return df_sentences[\"tokens_count\"].mean() # Your answer here\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What are the 5 most frequent parts of speech in this text? What is their frequency?\n",
    "\n",
    "*This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19204),\n",
       " ('the', 13715),\n",
       " ('.', 7308),\n",
       " ('of', 6513),\n",
       " ('and', 6010),\n",
       " ('a', 4545),\n",
       " ('to', 4515),\n",
       " (';', 4173),\n",
       " ('in', 3908),\n",
       " ('that', 2978),\n",
       " ('his', 2459),\n",
       " ('it', 2196),\n",
       " ('I', 2097),\n",
       " ('!', 1767),\n",
       " ('is', 1722),\n",
       " ('--', 1713),\n",
       " ('with', 1659),\n",
       " ('he', 1658),\n",
       " ('was', 1639),\n",
       " ('as', 1620),\n",
       " (\"''\", 1615),\n",
       " (\"'s\", 1585),\n",
       " ('``', 1456),\n",
       " ('all', 1444),\n",
       " ('for', 1413),\n",
       " ('this', 1280),\n",
       " ('at', 1230),\n",
       " ('not', 1170),\n",
       " ('by', 1135),\n",
       " ('but', 1110),\n",
       " ('him', 1058),\n",
       " ('from', 1052),\n",
       " ('be', 1027),\n",
       " ('?', 1004),\n",
       " ('on', 1003),\n",
       " ('so', 914),\n",
       " ('one', 880),\n",
       " ('you', 841),\n",
       " ('whale', 782),\n",
       " ('had', 767),\n",
       " ('have', 763),\n",
       " ('there', 710),\n",
       " ('But', 703),\n",
       " ('or', 697),\n",
       " ('were', 679),\n",
       " ('now', 645),\n",
       " ('which', 640),\n",
       " ('me', 624),\n",
       " ('their', 612),\n",
       " ('The', 603),\n",
       " ('are', 586),\n",
       " ('they', 586),\n",
       " ('an', 582),\n",
       " ('some', 578),\n",
       " ('then', 570),\n",
       " ('my', 564),\n",
       " ('like', 558),\n",
       " ('when', 553),\n",
       " ('upon', 537),\n",
       " ('into', 519),\n",
       " ('out', 518),\n",
       " ('more', 500),\n",
       " ('up', 499),\n",
       " ('Ahab', 498),\n",
       " ('no', 483),\n",
       " ('man', 472),\n",
       " ('them', 471),\n",
       " ('ship', 454),\n",
       " ('what', 438),\n",
       " ('old', 429),\n",
       " ('ye', 427),\n",
       " ('would', 425),\n",
       " ('if', 421),\n",
       " ('been', 415),\n",
       " ('we', 411),\n",
       " ('other', 409),\n",
       " ('over', 397),\n",
       " ('these', 381),\n",
       " ('will', 377),\n",
       " ('its', 372),\n",
       " ('And', 367),\n",
       " ('sea', 365),\n",
       " ('do', 363),\n",
       " ('only', 360),\n",
       " ('down', 355),\n",
       " ('such', 336),\n",
       " ('though', 335),\n",
       " ('her', 329),\n",
       " ('any', 320),\n",
       " ('who', 318),\n",
       " ('time', 316),\n",
       " ('very', 311),\n",
       " ('than', 309),\n",
       " ('It', 308),\n",
       " ('long', 305),\n",
       " ('about', 304),\n",
       " ('said', 302),\n",
       " ('still', 299),\n",
       " ('yet', 299),\n",
       " ('those', 297),\n",
       " ('before', 293),\n",
       " ('has', 291),\n",
       " ('great', 290),\n",
       " ('must', 283),\n",
       " ('seemed', 283),\n",
       " ('boat', 281),\n",
       " ('most', 276),\n",
       " ('two', 275),\n",
       " ('last', 275),\n",
       " ('here', 270),\n",
       " ('head', 270),\n",
       " ('Whale', 270),\n",
       " ('did', 264),\n",
       " ('way', 262),\n",
       " ('can', 256),\n",
       " (\"'\", 252),\n",
       " ('again', 252),\n",
       " ('Queequeg', 252),\n",
       " ('Stubb', 252),\n",
       " ('see', 250),\n",
       " (\"n't\", 250),\n",
       " ('after', 247),\n",
       " ('little', 247),\n",
       " ('your', 240),\n",
       " ('round', 240),\n",
       " ('whales', 236),\n",
       " ('say', 235),\n",
       " ('In', 235),\n",
       " ('thou', 231),\n",
       " ('men', 231),\n",
       " ('three', 231),\n",
       " ('may', 229),\n",
       " ('us', 228),\n",
       " ('He', 227),\n",
       " ('through', 226),\n",
       " ('every', 222),\n",
       " ('could', 221),\n",
       " ('being', 219),\n",
       " ('much', 218),\n",
       " ('while', 216),\n",
       " ('(', 215),\n",
       " (')', 215),\n",
       " ('Captain', 213),\n",
       " ('off', 210),\n",
       " ('first', 210),\n",
       " ('same', 210),\n",
       " ('own', 205),\n",
       " ('himself', 203),\n",
       " ('our', 198),\n",
       " ('For', 197),\n",
       " (':', 196),\n",
       " ('never', 195),\n",
       " ('hand', 194),\n",
       " ('Starbuck', 193),\n",
       " ('ever', 190),\n",
       " ('side', 189),\n",
       " ('thing', 188),\n",
       " ('where', 188),\n",
       " ('how', 187),\n",
       " ('almost', 186),\n",
       " ('might', 183),\n",
       " ('too', 182),\n",
       " ('go', 180),\n",
       " ('should', 180),\n",
       " ('even', 179),\n",
       " ('good', 178),\n",
       " ('made', 177),\n",
       " ('away', 172),\n",
       " ('world', 166),\n",
       " ('well', 166),\n",
       " ('water', 166),\n",
       " ('Pequod', 164),\n",
       " ('What', 163),\n",
       " ('many', 161),\n",
       " ('seen', 160),\n",
       " ('deck', 159),\n",
       " ('among', 158),\n",
       " ('white', 158),\n",
       " ('day', 157),\n",
       " ('eyes', 155),\n",
       " ('far', 155),\n",
       " ('cried', 155),\n",
       " ('without', 154),\n",
       " ('sort', 152),\n",
       " ('come', 150),\n",
       " ('CHAPTER', 150),\n",
       " ('A', 149),\n",
       " ('know', 149),\n",
       " ('thought', 148),\n",
       " ('part', 148),\n",
       " ('back', 146),\n",
       " ('So', 145),\n",
       " ('There', 144),\n",
       " ('once', 144),\n",
       " ('sir', 143),\n",
       " ('boats', 142),\n",
       " ('Now', 139),\n",
       " ('crew', 139),\n",
       " ('air', 138),\n",
       " ('whole', 136),\n",
       " ('life', 135),\n",
       " ('look', 134),\n",
       " ('Sperm', 133),\n",
       " ('against', 132),\n",
       " ('things', 132),\n",
       " ('came', 130),\n",
       " ('night', 130),\n",
       " ('thee', 129),\n",
       " ('God', 129),\n",
       " ('each', 127),\n",
       " ('feet', 125),\n",
       " ('hands', 122),\n",
       " ('small', 121),\n",
       " ('As', 120),\n",
       " ('till', 120),\n",
       " ('something', 119),\n",
       " ('take', 118),\n",
       " ('let', 118),\n",
       " ('tell', 118),\n",
       " ('both', 118),\n",
       " ('Oh', 117),\n",
       " ('between', 117),\n",
       " ('found', 115),\n",
       " ('under', 115),\n",
       " ('called', 113),\n",
       " ('soon', 113),\n",
       " ('full', 111),\n",
       " ('saw', 111),\n",
       " ('place', 111),\n",
       " ('times', 111),\n",
       " ('body', 110),\n",
       " ('just', 110),\n",
       " ('along', 110),\n",
       " ('think', 109),\n",
       " ('make', 109),\n",
       " ('captain', 109),\n",
       " ('heard', 109),\n",
       " ('line', 108),\n",
       " ('towards', 107),\n",
       " ('thus', 107),\n",
       " ('another', 106),\n",
       " (\"'ll\", 106),\n",
       " ('moment', 105),\n",
       " ('thy', 105),\n",
       " ('This', 104),\n",
       " ('poor', 104),\n",
       " ('sight', 104),\n",
       " ('Flask', 104),\n",
       " ('fish', 103),\n",
       " ('she', 103),\n",
       " ('nothing', 102),\n",
       " ('sperm', 102),\n",
       " ('whaling', 99),\n",
       " ('THE', 98),\n",
       " ('went', 97),\n",
       " ('No', 96),\n",
       " ('strange', 95),\n",
       " ('end', 95),\n",
       " ('face', 94),\n",
       " ('high', 93),\n",
       " ('few', 92),\n",
       " ('get', 92),\n",
       " ('voyage', 91),\n",
       " ('does', 91),\n",
       " ('sun', 91),\n",
       " ('dead', 90),\n",
       " ('years', 89),\n",
       " ('right', 89),\n",
       " ('half', 89),\n",
       " ('stood', 89),\n",
       " ('White', 89),\n",
       " ('also', 88),\n",
       " ('heart', 87),\n",
       " ('certain', 87),\n",
       " ('whose', 86),\n",
       " ('hold', 86),\n",
       " ('matter', 85),\n",
       " ('leg', 85),\n",
       " ('am', 84),\n",
       " ('shall', 84),\n",
       " ('That', 84),\n",
       " ('seems', 84),\n",
       " ('arm', 84),\n",
       " ('Nantucket', 84),\n",
       " ('itself', 84),\n",
       " ('seem', 84),\n",
       " ('At', 84),\n",
       " ('Jonah', 83),\n",
       " ('Aye', 83),\n",
       " ('Moby', 82),\n",
       " ('Dick', 82),\n",
       " ('eye', 82),\n",
       " ('perhaps', 82),\n",
       " ('soul', 82),\n",
       " ('indeed', 82),\n",
       " ('sometimes', 81),\n",
       " ('known', 80),\n",
       " ('however', 80),\n",
       " ('seas', 80),\n",
       " ('always', 80),\n",
       " ('wild', 80),\n",
       " ('sail', 79),\n",
       " ('going', 79),\n",
       " ('nor', 79),\n",
       " ('black', 79),\n",
       " ('present', 79),\n",
       " ('within', 78),\n",
       " ('length', 78),\n",
       " ('They', 78),\n",
       " ('oil', 78),\n",
       " ('mind', 78),\n",
       " ('ships', 77),\n",
       " ('days', 77),\n",
       " ('stand', 77),\n",
       " ('instant', 77),\n",
       " ('word', 76),\n",
       " ('whether', 76),\n",
       " ('large', 76),\n",
       " ('hard', 76),\n",
       " ('Bildad', 76),\n",
       " ('least', 75),\n",
       " ('tail', 75),\n",
       " ('young', 75),\n",
       " ('iron', 75),\n",
       " ('beneath', 74),\n",
       " ('enough', 74),\n",
       " ('Nor', 74),\n",
       " ('done', 74),\n",
       " ('Peleg', 74),\n",
       " ('true', 73),\n",
       " ('land', 73),\n",
       " ('vast', 73),\n",
       " ('living', 73),\n",
       " ('set', 73),\n",
       " ('harpooneer', 73),\n",
       " ('because', 73),\n",
       " ('light', 73),\n",
       " ('standing', 73),\n",
       " ('put', 72),\n",
       " ('harpoon', 72),\n",
       " ('bed', 72),\n",
       " ('give', 71),\n",
       " ('why', 71),\n",
       " ('cabin', 71),\n",
       " ('near', 69),\n",
       " ('name', 68),\n",
       " ('four', 68),\n",
       " ('open', 68),\n",
       " ('myself', 68),\n",
       " ('whalemen', 68),\n",
       " ('mate', 68),\n",
       " ('rather', 68),\n",
       " ('morning', 68),\n",
       " ('often', 68),\n",
       " ('aye', 68),\n",
       " ('case', 67),\n",
       " ('lay', 67),\n",
       " ('wind', 66),\n",
       " ('point', 66),\n",
       " ('left', 66),\n",
       " ('business', 66),\n",
       " ('ere', 66),\n",
       " ('turned', 66),\n",
       " ('keep', 66),\n",
       " ('waters', 66),\n",
       " ('Pip', 66),\n",
       " ('deep', 65),\n",
       " ('fire', 65),\n",
       " ('How', 65),\n",
       " ('Leviathan', 64),\n",
       " ('together', 64),\n",
       " ('order', 64),\n",
       " ('general', 64),\n",
       " ('reason', 64),\n",
       " ('looked', 64),\n",
       " ('ocean', 63),\n",
       " ('since', 63),\n",
       " ('best', 62),\n",
       " ('board', 62),\n",
       " ('having', 62),\n",
       " ('To', 61),\n",
       " ('hear', 60),\n",
       " ('If', 60),\n",
       " ('death', 60),\n",
       " ('better', 60),\n",
       " ('themselves', 59),\n",
       " ('further', 59),\n",
       " ('live', 59),\n",
       " ('gone', 58),\n",
       " ('mouth', 58),\n",
       " ('work', 58),\n",
       " ('With', 58),\n",
       " ('Mr.', 58),\n",
       " ('lower', 57),\n",
       " ('feel', 56),\n",
       " ('peculiar', 56),\n",
       " ('home', 56),\n",
       " ('fine', 56),\n",
       " ('chase', 56),\n",
       " ('dark', 56),\n",
       " ('therefore', 56),\n",
       " ('find', 55),\n",
       " ('Indian', 55),\n",
       " ('harpooneers', 55),\n",
       " ('looking', 55),\n",
       " ('Then', 55),\n",
       " ('All', 55),\n",
       " ('entire', 55),\n",
       " ('goes', 54),\n",
       " ('above', 54),\n",
       " ('turn', 54),\n",
       " ('jaw', 54),\n",
       " ('short', 54),\n",
       " ('Well', 54),\n",
       " ('second', 54),\n",
       " ('His', 54),\n",
       " ('Tashtego', 54),\n",
       " ('aloft', 53),\n",
       " ('began', 53),\n",
       " ('curious', 53),\n",
       " ('craft', 52),\n",
       " ('forth', 52),\n",
       " ('savage', 52),\n",
       " ('bottom', 52),\n",
       " ('When', 52),\n",
       " ('comes', 52),\n",
       " ('call', 52),\n",
       " ('By', 51),\n",
       " ('close', 51),\n",
       " ('run', 51),\n",
       " ('blood', 51),\n",
       " ('less', 51),\n",
       " ('turning', 51),\n",
       " ('broad', 51),\n",
       " ('fishery', 51),\n",
       " ('vessel', 50),\n",
       " ('behind', 50),\n",
       " ('taken', 50),\n",
       " ('hundred', 50),\n",
       " ('Right', 50),\n",
       " ('thousand', 50),\n",
       " ('taking', 50),\n",
       " ('sailors', 50),\n",
       " ('rest', 50),\n",
       " (\"'S\", 49),\n",
       " ('coming', 49),\n",
       " ('OF', 49),\n",
       " ('sharks', 49),\n",
       " ('particular', 49),\n",
       " ('took', 49),\n",
       " ('ivory', 49),\n",
       " ('devil', 48),\n",
       " ('Here', 48),\n",
       " ('waves', 48),\n",
       " ('Look', 48),\n",
       " ('used', 48),\n",
       " ('bows', 48),\n",
       " ('mighty', 47),\n",
       " ('Not', 47),\n",
       " ('Do', 47),\n",
       " ('slowly', 47),\n",
       " ('story', 47),\n",
       " ('New', 47),\n",
       " ('Though', 47),\n",
       " ('common', 47),\n",
       " ('kept', 47),\n",
       " ('stranger', 47),\n",
       " ('earth', 46),\n",
       " ('view', 46),\n",
       " ('stern', 46),\n",
       " ('cut', 46),\n",
       " ('voice', 46),\n",
       " ('speak', 46),\n",
       " ('green', 46),\n",
       " ('fellow', 46),\n",
       " ('English', 46),\n",
       " ('forward', 46),\n",
       " ('On', 46),\n",
       " ('Yes', 46),\n",
       " ('sailor', 46),\n",
       " ('else', 46),\n",
       " ('broken', 46),\n",
       " ('mark', 46),\n",
       " ('got', 46),\n",
       " ('next', 46),\n",
       " ('several', 46),\n",
       " ('below', 46),\n",
       " ('spout', 46),\n",
       " ('touching', 45),\n",
       " ('monster', 45),\n",
       " ('bones', 45),\n",
       " ('lost', 45),\n",
       " ('sat', 45),\n",
       " ('struck', 45),\n",
       " ('Yet', 45),\n",
       " ('ten', 45),\n",
       " ('Why', 45),\n",
       " ('suddenly', 45),\n",
       " ('fact', 45),\n",
       " ('fast', 45),\n",
       " ('queer', 44),\n",
       " ('whatever', 44),\n",
       " ('Lord', 44),\n",
       " ('teeth', 44),\n",
       " ('noble', 44),\n",
       " ('chance', 44),\n",
       " ('We', 44),\n",
       " ('told', 44),\n",
       " ('caught', 44),\n",
       " ('form', 44),\n",
       " ('wide', 44),\n",
       " ('sure', 44),\n",
       " ('rope', 44),\n",
       " ('especially', 44),\n",
       " ('straight', 44),\n",
       " ('sleep', 44),\n",
       " ('says', 44),\n",
       " ('mine', 44),\n",
       " ('You', 44),\n",
       " ('room', 44),\n",
       " ('means', 44),\n",
       " ('somehow', 43),\n",
       " ('whom', 43),\n",
       " ('knew', 43),\n",
       " ('nigh', 43),\n",
       " ('rolled', 43),\n",
       " ('heads', 43),\n",
       " ('whaleman', 43),\n",
       " ('mere', 42),\n",
       " ('making', 42),\n",
       " ('people', 42),\n",
       " ('hours', 42),\n",
       " ('grand', 42),\n",
       " ('watch', 42),\n",
       " ('door', 42),\n",
       " ('seamen', 42),\n",
       " ('running', 42),\n",
       " ('sudden', 42),\n",
       " ('creature', 42),\n",
       " ('surface', 42),\n",
       " ('calm', 41),\n",
       " ('lance', 41),\n",
       " ('blue', 41),\n",
       " ('quite', 41),\n",
       " ('cook', 41),\n",
       " ('anything', 41),\n",
       " ('passed', 41),\n",
       " ('parts', 41),\n",
       " ('sharp', 41),\n",
       " ('felt', 41),\n",
       " ('course', 41),\n",
       " ('sound', 41),\n",
       " ('wondrous', 41),\n",
       " ('wake', 40),\n",
       " ('Who', 40),\n",
       " (\"'em\", 40),\n",
       " ('saying', 40),\n",
       " ('brow', 40),\n",
       " ('Steelkilt', 40),\n",
       " ('clear', 39),\n",
       " ('art', 39),\n",
       " ('plainly', 39),\n",
       " ('either', 39),\n",
       " ('distance', 39),\n",
       " ('bow', 39),\n",
       " ('object', 39),\n",
       " ('mass', 39),\n",
       " ('mortal', 39),\n",
       " ('boy', 39),\n",
       " ('purpose', 39),\n",
       " ('hour', 39),\n",
       " ('mates', 39),\n",
       " ('makes', 39),\n",
       " ('leaving', 38),\n",
       " ('brought', 38),\n",
       " ('Some', 38),\n",
       " ('single', 38),\n",
       " ('sailed', 38),\n",
       " ('cry', 38),\n",
       " ('darted', 38),\n",
       " ('concerning', 38),\n",
       " ('gave', 38),\n",
       " ('others', 37),\n",
       " ('alone', 37),\n",
       " ('Thou', 37),\n",
       " ('Let', 37),\n",
       " ('AND', 37),\n",
       " ('fixed', 37),\n",
       " ('heaven', 37),\n",
       " ('manner', 37),\n",
       " ('mean', 37),\n",
       " ('plain', 37),\n",
       " ('five', 37),\n",
       " ('help', 37),\n",
       " ('held', 37),\n",
       " ('hat', 37),\n",
       " ('power', 37),\n",
       " ('gentlemen', 37),\n",
       " ('pull', 37),\n",
       " ('placed', 36),\n",
       " ('ago', 36),\n",
       " ('around', 36),\n",
       " ('fell', 36),\n",
       " ('new', 36),\n",
       " ('bulwarks', 36),\n",
       " ('easy', 36),\n",
       " ('various', 36),\n",
       " ('bone', 36),\n",
       " ('forehead', 36),\n",
       " ('ready', 36),\n",
       " ('unknown', 36),\n",
       " ('flukes', 36),\n",
       " ('aspect', 36),\n",
       " ('oh', 36),\n",
       " ('use', 36),\n",
       " ('sails', 36),\n",
       " ('given', 36),\n",
       " ('ground', 36),\n",
       " ('carpenter', 36),\n",
       " ('oars', 36),\n",
       " ('book', 35),\n",
       " ('coast', 35),\n",
       " ('Greenland', 35),\n",
       " ('legs', 35),\n",
       " ('famous', 35),\n",
       " ('sign', 35),\n",
       " ('suppose', 35),\n",
       " ('human', 35),\n",
       " (\"'ve\", 35),\n",
       " ('gold', 35),\n",
       " ('brain', 34),\n",
       " ('WHALE', 34),\n",
       " ('nature', 34),\n",
       " ('pipe', 34),\n",
       " ('mast-head', 34),\n",
       " ('American', 34),\n",
       " ('shot', 34),\n",
       " ('previous', 34),\n",
       " ('forecastle', 34),\n",
       " ('Such', 34),\n",
       " ('Cape', 34),\n",
       " ('middle', 34),\n",
       " ('holding', 34),\n",
       " ('thoughts', 34),\n",
       " ('mad', 34),\n",
       " ('heavy', 34),\n",
       " ('arms', 34),\n",
       " ('turns', 34),\n",
       " ('remained', 34),\n",
       " ('Daggoo', 34),\n",
       " ('strong', 33),\n",
       " ('fifty', 33),\n",
       " ('killed', 33),\n",
       " ('creatures', 33),\n",
       " ('ashore', 33),\n",
       " ('nearly', 33),\n",
       " ('boys', 33),\n",
       " ('idea', 33),\n",
       " ('house', 33),\n",
       " ('company', 33),\n",
       " ('hammock', 33),\n",
       " ('none', 33),\n",
       " ('completely', 33),\n",
       " ('top', 33),\n",
       " ('skeleton', 33),\n",
       " (\"'ye\", 33),\n",
       " ('sailing', 33),\n",
       " ('rolling', 32),\n",
       " ('bulk', 32),\n",
       " ('doubt', 32),\n",
       " ('fear', 32),\n",
       " ('passage', 32),\n",
       " ('Pacific', 32),\n",
       " ('coffin', 32),\n",
       " ('account', 32),\n",
       " ('rigging', 32),\n",
       " ('bear', 32),\n",
       " ('low', 32),\n",
       " ('lines', 32),\n",
       " ('table', 32),\n",
       " ('want', 32),\n",
       " ('wonder', 32),\n",
       " ('skin', 32),\n",
       " ('drawing', 32),\n",
       " ('show', 32),\n",
       " ('proper', 32),\n",
       " ('intervals', 32),\n",
       " ('SAILOR', 32),\n",
       " ('miles', 31),\n",
       " ('species', 31),\n",
       " ('mast-heads', 31),\n",
       " ('quick', 31),\n",
       " ('darkness', 31),\n",
       " ('red', 31),\n",
       " ('jet', 31),\n",
       " ('leviathan', 31),\n",
       " ('visible', 31),\n",
       " ('planks', 31),\n",
       " ('weather', 31),\n",
       " ('hardly', 31),\n",
       " ('substance', 31),\n",
       " ('helm', 31),\n",
       " ('across', 31),\n",
       " ('aft', 31),\n",
       " ('nose', 31),\n",
       " ('except', 31),\n",
       " ('natural', 31),\n",
       " ('While', 30),\n",
       " ('generally', 30),\n",
       " ('fresh', 30),\n",
       " ('possible', 30),\n",
       " ('upper', 30),\n",
       " ('Besides', 30),\n",
       " ('act', 30),\n",
       " ('really', 30),\n",
       " ('fair', 30),\n",
       " ('soft', 30),\n",
       " ('truth', 30),\n",
       " ('sky', 30),\n",
       " ('carried', 30),\n",
       " ('cast', 30),\n",
       " ('die', 30),\n",
       " ('hull', 30),\n",
       " ('instances', 30),\n",
       " ('altogether', 29),\n",
       " ('Whales', 29),\n",
       " ('swimming', 29),\n",
       " ('huge', 29),\n",
       " ('jaws', 29),\n",
       " ('steel', 29),\n",
       " ('entirely', 29),\n",
       " ('late', 29),\n",
       " ('possibly', 29),\n",
       " ('smoke', 29),\n",
       " ('vain', 29),\n",
       " ('unless', 29),\n",
       " ('mast', 29),\n",
       " ('cold', 29),\n",
       " ('foot', 29),\n",
       " ('tossed', 29),\n",
       " ('final', 29),\n",
       " ('harpoons', 29),\n",
       " ('stands', 29),\n",
       " ('mariners', 29),\n",
       " ('touch', 29),\n",
       " ('wood', 29),\n",
       " ('question', 29),\n",
       " ('pass', 29),\n",
       " ('strangely', 29),\n",
       " ('hammer', 29),\n",
       " ('rising', 29),\n",
       " ('de', 29),\n",
       " ('hoisted', 29),\n",
       " ('ancient', 28),\n",
       " ('strike', 28),\n",
       " ('One', 28),\n",
       " ('try', 28),\n",
       " ('fishermen', 28),\n",
       " ('free', 28),\n",
       " ('Sir', 28),\n",
       " ('pretty', 28),\n",
       " ('knows', 28),\n",
       " ('mild', 28),\n",
       " ('considering', 28),\n",
       " ('astern', 28),\n",
       " ('already', 28),\n",
       " ('words', 28),\n",
       " ('hung', 28),\n",
       " ('become', 28),\n",
       " ('feeling', 28),\n",
       " ('third', 28),\n",
       " ('glance', 28),\n",
       " ('O', 28),\n",
       " ('start', 28),\n",
       " ('leeward', 28),\n",
       " ('Parsee', 28),\n",
       " ('hearts', 27),\n",
       " ('sides', 27),\n",
       " ('kind', 27),\n",
       " ('Where', 27),\n",
       " ('gale', 27),\n",
       " ('precisely', 27),\n",
       " ('quarter-deck', 27),\n",
       " ('landlord', 27),\n",
       " ('somewhat', 27),\n",
       " ('certainly', 27),\n",
       " ('seeing', 27),\n",
       " ('person', 27),\n",
       " ('Come', 27),\n",
       " ('wo', 27),\n",
       " ('eyeing', 27),\n",
       " ('hope', 27),\n",
       " ('Nevertheless', 27),\n",
       " ('looks', 27),\n",
       " ('overboard', 27),\n",
       " ('sideways', 27),\n",
       " ('command', 27),\n",
       " ('dropped', 27),\n",
       " ('wholly', 27),\n",
       " ('born', 27),\n",
       " ('ahead', 27),\n",
       " ('alongside', 27),\n",
       " ('Fedallah', 27),\n",
       " ('play', 26),\n",
       " ('received', 26),\n",
       " ('lie', 26),\n",
       " ('royal', 26),\n",
       " (\"'d\", 26),\n",
       " ('enormous', 26),\n",
       " ('island', 26),\n",
       " ('King', 26),\n",
       " ('degree', 26),\n",
       " ('yourself', 26),\n",
       " ('considerable', 26),\n",
       " ('circumstances', 26),\n",
       " ('started', 26),\n",
       " ('followed', 26),\n",
       " ('flying', 26),\n",
       " ('wooden', 26),\n",
       " ('ears', 26),\n",
       " ('fancy', 26),\n",
       " ('Upon', 26),\n",
       " ('getting', 26),\n",
       " ('yes', 26),\n",
       " ('otherwise', 26),\n",
       " ('giving', 26),\n",
       " ('circumstance', 26),\n",
       " ('read', 26),\n",
       " ('From', 26),\n",
       " ('bodily', 26),\n",
       " ('suspended', 26),\n",
       " ('pointed', 26),\n",
       " ('blow', 26),\n",
       " ('blubber', 26),\n",
       " ('whiteness', 26),\n",
       " ('yards', 25),\n",
       " ('learned', 25),\n",
       " ('masts', 25),\n",
       " ('carry', 25),\n",
       " ('thrown', 25),\n",
       " ('front', 25),\n",
       " ('year', 25),\n",
       " ('bit', 25),\n",
       " ('whale-ship', 25),\n",
       " ('silent', 25),\n",
       " ('leaning', 25),\n",
       " ('seated', 25),\n",
       " ('believe', 25),\n",
       " ('stop', 25),\n",
       " ('thick', 25),\n",
       " ('hump', 25),\n",
       " ('cases', 25),\n",
       " ('number', 25),\n",
       " ('added', 25),\n",
       " ('supper', 25),\n",
       " ('chest', 25),\n",
       " ('interval', 25),\n",
       " ('duty', 25),\n",
       " ('thinking', 25),\n",
       " ('similar', 25),\n",
       " ('skull', 25),\n",
       " ('takes', 25),\n",
       " ('scene', 25),\n",
       " ('complete', 25),\n",
       " ('Thus', 25),\n",
       " ('woe', 25),\n",
       " ('bearing', 25),\n",
       " ('twenty', 25),\n",
       " ('whale-boat', 25),\n",
       " ('steady', 25),\n",
       " ('coat', 24),\n",
       " ('warm', 24),\n",
       " ('grow', 24),\n",
       " ('king', 24),\n",
       " ('dart', 24),\n",
       " ('thirty', 24),\n",
       " ('floating', 24),\n",
       " ('seldom', 24),\n",
       " ('love', 24),\n",
       " ('bright', 24),\n",
       " ('Dutch', 24),\n",
       " ('different', 24),\n",
       " ('regular', 24),\n",
       " ('pursuit', 24),\n",
       " ('storm', 24),\n",
       " ('watery', 24),\n",
       " ('chief', 24),\n",
       " ('drop', 24),\n",
       " ('orders', 24),\n",
       " ('exactly', 24),\n",
       " ('perils', 24),\n",
       " ('became', 24),\n",
       " ('afterwards', 24),\n",
       " ('swift', 24),\n",
       " (\"'m\", 24),\n",
       " ('Of', 24),\n",
       " ('First', 24),\n",
       " ('ran', 24),\n",
       " ('aside', 24),\n",
       " ('escape', 24),\n",
       " ('friend', 24),\n",
       " ('hinted', 24),\n",
       " ('hunters', 24),\n",
       " ('spread', 24),\n",
       " ('d', 24),\n",
       " ('thyself', 24),\n",
       " ('Stand', 24),\n",
       " ('remains', 24),\n",
       " ('keel', 24),\n",
       " ('oar', 24),\n",
       " ('country', 23),\n",
       " ('six', 23),\n",
       " ('kill', 23),\n",
       " ('regarded', 23),\n",
       " ('blows', 23),\n",
       " ('vessels', 23),\n",
       " ('honour', 23),\n",
       " ('answer', 23),\n",
       " ('following', 23),\n",
       " ('port', 23),\n",
       " ('beyond', 23),\n",
       " ('nevertheless', 23),\n",
       " ('gods', 23),\n",
       " ('fiery', 23),\n",
       " ('midnight', 23),\n",
       " ('spring', 23),\n",
       " ('wall', 23),\n",
       " ('lances', 23),\n",
       " ('Is', 23),\n",
       " ('flew', 23),\n",
       " ('higher', 23),\n",
       " ('somewhere', 23),\n",
       " ('hot', 23),\n",
       " ('hidden', 23),\n",
       " ('during', 23),\n",
       " ('wife', 23),\n",
       " ('cutting', 23),\n",
       " ('flesh', 23),\n",
       " ('sweet', 23),\n",
       " ('instead', 23),\n",
       " ('beat', 23),\n",
       " ('rose', 23),\n",
       " ('chapter', 23),\n",
       " ('finally', 23),\n",
       " ('hence', 23),\n",
       " ('lad', 23),\n",
       " ('speaking', 23),\n",
       " ('circle', 23),\n",
       " ('strength', 23),\n",
       " ('remain', 23),\n",
       " ('secret', 23),\n",
       " ('hunt', 23),\n",
       " ('level', 23),\n",
       " ('*', 23),\n",
       " ('Lakeman', 23),\n",
       " ('Like', 22),\n",
       " ('battle', 22),\n",
       " ('forty', 22),\n",
       " ('answered', 22),\n",
       " ('stove', 22),\n",
       " ('lives', 22),\n",
       " ('rear', 22),\n",
       " ('drawn', 22),\n",
       " ('tall', 22),\n",
       " ('wonderful', 22),\n",
       " ('centre', 22),\n",
       " ('filled', 22),\n",
       " ('shipmates', 22),\n",
       " ('hole', 22),\n",
       " ('cause', 22),\n",
       " ('game', 22),\n",
       " ('real', 22),\n",
       " ('owing', 22),\n",
       " ('alive', 22),\n",
       " ('drew', 22),\n",
       " ('commanded', 22),\n",
       " ('deadly', 22),\n",
       " ('hint', 22),\n",
       " ('descried', 22),\n",
       " ('souls', 22),\n",
       " ('Nantucketer', 22),\n",
       " ('windward', 22),\n",
       " ('shark', 22),\n",
       " ('dashed', 22),\n",
       " ('fin', 22),\n",
       " ('pulling', 22),\n",
       " ('Radney', 22),\n",
       " ('shore', 21),\n",
       " ('TO', 21),\n",
       " ('ca', 21),\n",
       " ('magnitude', 21),\n",
       " (\"'t\", 21),\n",
       " ('My', 21),\n",
       " ('striking', 21),\n",
       " ('These', 21),\n",
       " ('bound', 21),\n",
       " ('decks', 21),\n",
       " ('formed', 21),\n",
       " ('original', 21),\n",
       " ('Ha', 21),\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dist.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 3944), ('JJ', 2958), ('NNP', 2950), ('NNS', 2420), ('VBG', 1402)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eight():\n",
    "    tags = nltk.pos_tag(moby_words.token)\n",
    "    frequencies = FreqDist([tag for (word, tag) in tags])\n",
    "    return frequencies.most_common(5)\n",
    "\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Spelling Recommender\n",
    "\n",
    "For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
    "\n",
    "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
    "\n",
    "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
    "\n",
    "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "from nltk.metrics.distance import (\n",
    "    edit_distance,\n",
    "    jaccard_distance,\n",
    "    )\n",
    "from nltk.util import ngrams\n",
    "correct_spellings = words.words()\n",
    "spellings_series = pd.Series(correct_spellings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct_spellings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  nltk.metrics.distance\n",
    "#print(distance.jaccard_distance(set(list(\"corbugent\")), set(list(\"carbukent\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(\"carbukent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard(entries, gram_number):\n",
    "    \"\"\"find the closet words to each entry\n",
    "\n",
    "    Args:\n",
    "     entries: collection of words to match\n",
    "     gram_number: number of n-grams to use\n",
    "\n",
    "    Returns:\n",
    "     list: words with the closest jaccard distance to entries\n",
    "    \"\"\"\n",
    "    outcomes = []\n",
    "    for entry in entries:\n",
    "        spellings = spellings_series[spellings_series.str.startswith(entry[0])]\n",
    "        distances = ((jaccard_distance(set(ngrams(entry, gram_number)),\n",
    "                                       set(ngrams(word, gram_number))), word)\n",
    "                     for word in spellings)\n",
    "        closest = min(distances)\n",
    "        outcomes.append(closest[1])\n",
    "    return outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpulent', 'indecence', 'validate']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def answer_nine(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \"\"\"finds the closest word based on jaccard distance\"\"\"\n",
    "    return jaccard(entries, 3)\n",
    "    \n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cormus', 'incendiary', 'valid']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_ten(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    \n",
    "    return jaccard(entries, 4)\n",
    "    \n",
    "answer_ten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpulent', 'intendence', 'validate']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eleven(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    \n",
    "    outcomes = []\n",
    "    for entry in entries:\n",
    "        distances = ((edit_distance(entry,\n",
    "                                    word), word)\n",
    "                     for word in correct_spellings)\n",
    "        closest = min(distances)\n",
    "        outcomes.append(closest[1])\n",
    "    return outcomes\n",
    "\n",
    "answer_eleven()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "r35En",
   "launcher_item_id": "tCVfW",
   "part_id": "NTVgL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
